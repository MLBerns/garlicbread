{
  "name": "s3",
  "version": "1.3.0",
  "description": "high level amazon s3 client. upload and download files and directories",
  "main": "index.js",
  "scripts": {
    "test": "mocha"
  },
  "repository": {
    "type": "git",
    "url": "https://github.com/superjoe30/node-s3-client"
  },
  "keywords": [
    "amazon",
    "s3",
    "sync",
    "folder",
    "directory",
    "retry",
    "limit",
    "stream",
    "async"
  ],
  "author": {
    "name": "Andrew Kelley"
  },
  "license": "BSD",
  "devDependencies": {
    "mocha": "^1.18.2",
    "ncp": "^0.5.1"
  },
  "dependencies": {
    "aws-sdk": "^2.0.0-rc.18",
    "findit": "^1.2.0",
    "pend": "^1.1.1",
    "stream-counter": "^1.0.0",
    "mkdirp": "^0.5.0",
    "rimraf": "^2.2.8",
    "quotemeta": "0.0.0"
  },
  "readme": "# High Level Amazon S3 Client\n\n## Features and Limitations\n\n * Automatically retry a configurable number of times when S3 returns an error.\n * Includes logic to make multiple requests when there is a 1000 object limit.\n * Ability to set a limit on the maximum parallelization of S3 requests.\n   Retries get pushed to the end of the paralellization queue.\n * Ability to sync a dir to and from S3.\n * Progress reporting.\n * Limited to files less than 5GB.\n * Limited to objects which were not uploaded using a multipart request.\n\nSee also the companion CLI tool, [s3-cli](https://github.com/andrewrk/node-s3-cli).\n\n## Synopsis\n\n### Create a client\n\n```js\nvar s3 = require('s3');\n\nvar client = s3.createClient({\n  maxAsyncS3: Infinity,\n  s3RetryCount: 3,\n  s3RetryDelay: 1000,\n  s3Options: {\n    accessKeyId: \"your s3 key\",\n    secretAccessKey: \"your s3 secret\",\n    // any other options are passed to new AWS.S3()\n    // See: http://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/Config.html#constructor-property\n  },\n});\n```\n\n### Create a client from existing AWS.S3 object\n\n```js\nvar s3 = require('s3');\nvar awsS3Client = new AWS.S3(s3Options);\nvar options = {\n  s3Client: awsS3Client,\n};\nvar client = s3.fromAwsSdkS3(options);\n```\n\n### Upload a file to S3\n\n```js\nvar params = {\n  localFile: \"some/local/file\",\n\n  s3Params: {\n    Bucket: \"s3 bucket name\",\n    Key: \"some/remote/file\",\n    // other options supported by putObject, except Body and ContentLength.\n    // See: http://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/S3.html#putObject-property\n  },\n};\nvar uploader = client.uploadFile(params);\nuploader.on('error', function(err) {\n  console.error(\"unable to upload:\", err.stack);\n});\nuploader.on('progress', function() {\n  console.log(\"progress\", uploader.progressMd5Amount,\n            uploader.progressAmount, uploader.progressTotal);\n});\nuploader.on('end', function() {\n  console.log(\"done uploading\");\n});\n```\n\n### Download a file from S3\n\n```js\nvar params = {\n  localFile: \"some/local/file\",\n\n  s3Params: {\n    Bucket: \"s3 bucket name\",\n    Key: \"some/remote/file\",\n    // other options supported by getObject\n    // See: http://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/S3.html#getObject-property\n  },\n};\nvar downloader = client.downloadFile(params);\ndownloader.on('error', function(err) {\n  console.error(\"unable to download:\", err.stack);\n});\ndownloader.on('progress', function() {\n  console.log(\"progress\", downloader.progressAmount, downloader.progressTotal);\n});\ndownloader.on('end', function() {\n  console.log(\"done downloading\");\n});\n```\n\n### Sync a directory to S3\n\n```js\nvar params = {\n  localDir: \"some/local/dir\",\n  deleteRemoved: true, // default false, whether to remove s3 objects\n                       // that have no corresponding local file.\n\n  s3Params: {\n    Bucket: \"s3 bucket name\",\n    Prefix: \"some/remote/dir/\",\n    // other options supported by putObject, except Body and ContentLength.\n    // See: http://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/S3.html#putObject-property\n  },\n};\nvar uploader = client.uploadDir(params);\nuploader.on('error', function(err) {\n  console.error(\"unable to sync:\", err.stack);\n});\nuploader.on('progress', function() {\n  console.log(\"progress\", uploader.progressAmount, uploader.progressTotal);\n});\nuploader.on('end', function() {\n  console.log(\"done uploading\");\n});\n```\n\n## Tips\n\n * Consider adding [graceful-fs](https://github.com/isaacs/node-graceful-fs) to\n   your application. This will improve performance when using the `uploadDir`\n   and `downloadDir` functions.\n * Consider increasing the ulimit for the number of open files. This will also\n   improve performance when using the `uploadDir` and `downloadDir` functions.\n * Consider increasing the socket pool size in the `http` and `https` global\n   agents. This will improve bandwidth when using `uploadDir` and `downloadDir`\n   functions.\n\n## API Documentation\n\n### s3.createClient(options)\n\nCreates an S3 client.\n\n`options`:\n\n * `s3Client` - optional, an instance of `AWS.S3`. Leave blank if you provide `s3Options`.\n * `s3Options` - optional, provide this if you don't provide `s3Client`.\n   - See AWS SDK documentation for available options which are passed to `new AWS.S3()`:\n     http://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/Config.html#constructor-property\n * `maxAsyncS3` - maximum number of simultaneous requests this client will\n   ever have open to S3. defaults to `Infinity`.\n * `s3RetryCount` - how many times to try an S3 operation before giving up.\n * `s3RetryDelay` - how many milliseconds to wait before retrying an S3 operation.\n\n### s3.getPublicUrl(bucket, key, [insecure])\n\n * `bucket` S3 bucket\n * `key` S3 key\n * `insecure` boolean, whether to use http or https. defaults to false.\n\nreturns a string which looks like this:\n\n`https://s3.amazonaws.com/bucket/key`\n\n### client.uploadFile(params)\n\nSee http://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/S3.html#putObject-property\n\n`params`:\n\n * `s3Params`: params to pass to AWS SDK `putObject`.\n * `localFile`: path to the file on disk you want to upload to S3.\n * `localFileStat`: optional - if you happen to have the stat object from\n   `fs.stat` and the md5sum of the file, you can provide it here. Otherwise it\n   will be computed for you.\n\nThe difference between using AWS SDK `putObject` and this one:\n\n * This works with files, not streams or buffers.\n * If the reported MD5 upon upload completion does not match, it retries.\n * Retry based on the client's retry settings.\n * Progress reporting.\n\nReturns an `EventEmitter` with these properties:\n\n * `progressMd5Amount`\n * `progressAmount`\n * `progressTotal`\n\nAnd these events:\n\n * `'error' (err)`\n * `'end' (data)` - emitted when the file is uploaded successfully\n   - `data` is the same object that you get from `putObject` in AWS SDK\n * `'progress'` - emitted when `progressMd5Amount`, `progressAmount`, and\n   `progressTotal` properties change.\n * `'stream' (stream)` - emitted when a `ReadableStream` for `localFile` has\n   been opened. Be aware that this might fire multiple times if a request to S3\n   must be retried.\n\n### client.downloadFile(params)\n\nSee http://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/S3.html#getObject-property\n\n`params`:\n\n * `localFile` - the destination path on disk to write the s3 object into\n * `s3Params`: params to pass to AWS SDK `getObject`.\n\nThe difference between using AWS SDK `getObject` and this one:\n\n * This works with a destination file, not a stream or a buffer.\n * If the reported MD5 upon download completion does not match, it retries.\n * Retry based on the client's retry settings.\n * Progress reporting.\n\nReturns an `EventEmitter` with these properties:\n\n * `progressAmount`\n * `progressTotal`\n\nAnd these events:\n\n * `'error' (err)`\n * `'end'` - emitted when the file is uploaded successfully\n * `'progress'` - emitted when `progressAmount` and `progressTotal`\n   properties change.\n\n### client.listObjects(params)\n\nSee http://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/S3.html#listObjects-property\n\n`params`:\n\n * `recursive` - `true` or `false` whether or not you want to recurse\n   into directories.\n * `s3Params` - params to pass to AWS SDK `listObjects`.\n\nNote that if you set `Delimiter` in `s3Params` then you will get a list of\nobjects and folders in the directory you specify. You probably do not want to\nset `recursive` to `true` at the same time as specifying a `Delimiter` because\nthis will cause a request per directory. If you want all objects that share a\nprefix, leave the `Delimiter` option `null` or `undefined`.\n\nBe sure that `s3Params.Prefix` ends with a trailing slash (`/`) unless you\nare requesting the top-level listing, in which case `s3Params.Prefix` should\nbe empty string.\n\nThe difference between using AWS SDK `listObjects` and this one:\n\n * Retry based on the client's retry settings.\n * Supports recursive directory listing.\n * Make multiple requests if the number of objects to list is greater than 1000.\n\nReturns an `EventEmitter` with these properties:\n\n * `progressAmount`\n * `objectsFound`\n * `dirsFound`\n\nAnd these events:\n\n * `'error' (err)`\n * `'end'` - emitted when done listing and no more 'data' events will be emitted.\n * `'data' (data)` - emitted when a batch of objects are found. This is\n   the same as the `data` object in AWS SDK.\n * `'progress'` - emitted when `progressAmount`, `objectsFound`, and\n   `dirsFound` properties change.\n\nAnd these methods:\n\n * `abort()` - call this to stop the find operation.\n\n### client.deleteObjects(s3Params)\n\nSee http://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/S3.html#deleteObjects-property\n\n`s3Params` are the same.\n\nThe difference between using AWS SDK `deleteObjects` and this one is that this one will:\n\n * Retry based on the client's retry settings.\n * Make multiple requests if the number of objects you want to delete is\n   greater than 1000.\n\nReturns an `EventEmitter` with these properties:\n\n * `progressAmount`\n * `progressTotal`\n\nAnd these events:\n\n * `'error' (err)`\n * `'end'` - emitted when all objects are deleted.\n * `'progress'` - emitted when the `progressAmount` or `progressTotal` properties change.\n * `'data' (data)` - emitted when a request completes. There may be more.\n\n### client.uploadDir(params)\n\nSyncs an entire directory to S3.\n\n`params`:\n\n * `localDir` - source path on local file system to sync to S3\n * `deleteRemoved` - delete s3 objects with no corresponding local file.\n   default false\n * `getS3Params` - optional function which will be called for every file that\n   needs to be uploaded. See below.\n * `s3Params`\n   - `Prefix` (required)\n   - `Bucket` (required)\n\n```js\nfunction getS3Params(localFile, stat, callback) {\n  // call callback like this:\n  var err = new Error(...); // only if there is an error\n  var s3Params = { // if there is no error\n    ContentType: getMimeType(localFile), // just an example\n  };\n  // pass `null` for `s3Params` if you want to skip uploading this file.\n  callback(err, s3Params);\n}\n```\n\nReturns an `EventEmitter` with these properties:\n\n * `progressAmount`\n * `progressTotal`\n\nAnd these events:\n\n * `'error' (err)`\n * `'end'` - emitted when all files are uploaded\n * `'progress'` - emitted when the `progressAmount` or `progressTotal` properties change.\n\n### client.downloadDir(params)\n\nSyncs an entire directory from S3.\n\n`params`:\n\n * `localDir` - destination directory on local file system to sync to\n * `deleteRemoved` - delete local files with no corresponding s3 object. default `false`\n * `getS3Params` - optional function which will be called for every object that\n   needs to be downloaded. See below.\n * `s3Params`\n   - `Prefix` (required)\n   - `Bucket` (required)\n\n```js\nfunction getS3Params(localFile, s3Object, callback) {\n  // localFile is the destination path where the object will be written to\n  // s3Object is same as one element in the `Contents` array from here:\n  // http://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/S3.html#listObjects-property\n\n  // call callback like this:\n  var err = new Error(...); // only if there is an error\n  var s3Params = { // if there is no error\n    VersionId: \"abcd\", // just an example\n  };\n  // pass `null` for `s3Params` if you want to skip dowlnoading this object.\n  callback(err, s3Params);\n}\n```\n\nReturns an `EventEmitter` with these properties:\n\n * `progressAmount`\n * `progressTotal`\n\nAnd these events:\n\n * `'error' (err)`\n * `'end'` - emitted when all files are uploaded\n * `'progress'` - emitted when the `progressAmount` or `progressTotal` properties change.\n\n### client.deleteDir(s3Params)\n\nDeletes an entire directory on S3.\n\n`s3Params`:\n\n * `Bucket`\n * `Prefix`\n * `MFA` (optional)\n\nReturns an `EventEmitter` with these properties:\n\n * `progressAmount`\n * `progressTotal`\n\nAnd these events:\n\n * `'error' (err)`\n * `'end'` - emitted when all objects are deleted.\n * `'progress'` - emitted when the `progressAmount` or `progressTotal` properties change.\n\n### client.copyObject(s3Params)\n\nSee http://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/S3.html#copyObject-property\n\n`s3Params` are the same. Don't forget that `CopySource` must contain the\nsource bucket name as well as the source key name.\n\nThe difference between using AWS SDK `copyObject` and this one will:\n\n * Retry based on the client's retry settings.\n\nReturns an `EventEmitter` with these events:\n\n * `'error' (err)`\n * `'end' (data)`\n\n### client.moveObject(s3Params)\n\nSee http://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/S3.html#copyObject-property\n\n`s3Params` are the same. Don't forget that `CopySource` must contain the\nsource bucket name as well as the source key name.\n\nUnder the hood, this uses `copyObject` and then `deleteObjects` only if the\ncopy succeeded.\n\nReturns an `EventEmitter` with these events:\n\n * `'error' (err)`\n * `'copySuccess' (data)`\n * `'end' (data)`\n\n## Testing\n\n`S3_KEY=<valid_s3_key> S3_SECRET=<valid_s3_secret> S3_BUCKET=<valid_s3_bucket> npm test`\n\n## History\n\n### 1.3.0\n\n * `downloadFile` respects `maxAsyncS3`\n * Add `copyObject` API\n * AWS JS SDK updated to 2.0.0-rc.18\n * errors with `retryable` set to `false` are not retried\n * Add `moveObject` API\n * `uploadFile` emits a `stream` event.\n\n### 1.2.1\n\n * fix `listObjects` for greater than 1000 objects\n * `downloadDir` supports `getS3Params` parameter\n * `uploadDir` and `downloadDir` expose `objectsFound` progress\n\n### 1.2.0\n\n * `uploadDir` accepts `getS3Params` function parameter\n\n### 1.1.1\n\n * fix handling of directory seperator in Windows\n * allow `uploadDir` and `downloadDir` with empty `Prefix`\n\n### 1.1.0\n\n * Add an API function to get the HTTP url to an S3 resource\n\n### 1.0.0\n\n * complete module rewrite\n * depend on official AWS SDK instead of knox\n * support `uploadDir`, `downloadDir`, `listObjects`, `deleteObject`, and `deleteDir`\n\n### 0.3.1\n\n * fix `resp.req.url` sometimes not defined causing crash\n * fix emitting `end` event before write completely finished\n",
  "readmeFilename": "README.md",
  "bugs": {
    "url": "https://github.com/superjoe30/node-s3-client/issues"
  },
  "homepage": "https://github.com/superjoe30/node-s3-client",
  "_id": "s3@1.3.0",
  "dist": {
    "shasum": "c0960099bded1e50fc9d22d5fdf6a5f733fc53a1"
  },
  "_from": "s3@",
  "_resolved": "https://registry.npmjs.org/s3/-/s3-1.3.0.tgz"
}
